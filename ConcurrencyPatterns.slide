Concurrency Patterns in Go


Deepak Gunjetti
Software Architect @ Andcloud
deepak@andcloud.io
@dgunjetti

* Concurrent safe operation

- Synchronization primitives for sharing memory (sync.Mutex).

- Synchronication via communicating (channels)

- Immutable data

- Data protection by confinement

* Immutable data 

- Each concurrent process may operate on the same data, but it may not modify it. 

- code utilizes copies of values instead of pointers to values in memory.

* confinement

- Information is only  available from one concurrent process. 

- concurrent program is implicitly safe and no synchronization is needed. 

* Lexical confinement 

- only exposing read or write aspects of a channel to the concurrent processes that need them. 

- we don’t need to synchronize memory access or share data through communication.

* Lexical confinement 

.code -edit src/02-ConcurrencyPatterns/confinement01/main.go  /START1 OMIT/,/END1 OMIT/

.play -edit src/02-ConcurrencyPatterns/confinement01/main.go  /START2 OMIT/,/END2 OMIT/

* Lexical confinement... 

.play -edit src/02-ConcurrencyPatterns/confinement02/main.go  /START OMIT/,/END OMIT/


* Preventing Goroutine Leaks

- goroutines are not garbage collected by the runtime, we need to ensure they are cleaned up.


* Goroutines termination

- When it has completed its work.

- When it cannot continue its work due to an unrecoverable error.

- When it’s told to stop working.

* Cancellation of children goroutines 

- parent goroutine passes read-only channel to the child goroutine and then closes the channel when it wants to cancel the child goroutine.

* Cancellation..

.play -edit src/02-ConcurrencyPatterns/cancel/main.go  /START1 OMIT/,/END1 OMIT/

* Cancellation..

.play -edit src/02-ConcurrencyPatterns/cancel/main.go  /START2 OMIT/,/END2 OMIT/

* Cancellation..

- we pass the done channel to the doWork function. As a convention, this channel is the first parameter.

- for-select one of case statements is checking whether our done channel has been signaled. If it has, we return from the goroutine.

- we create a third goroutine to cancel the goroutine within doWork after a second. 

- We have successfully eliminated our goroutine leak.

* Cancelling producer goroutine 

.play -edit src/02-ConcurrencyPatterns/cancel02/main.go  /START1 OMIT/,/END1 OMIT/

* Cancelling producer goroutine..

.play -edit src/02-ConcurrencyPatterns/cancel02/main.go  /START2 OMIT/,/END2 OMIT/

* Cancelling producer goroutine..

- If a goroutine is responsible for creating a goroutine, it is also responsible for ensuring it can stop the goroutine.

* The or-channel

- At times you may find yourself wanting to combine one or more done channels into a single done channel that closes if any of its component channels close.

- you can combine these channels together using the or-channel pattern.

* The or-channel...

.code -edit src/02-ConcurrencyPatterns/orChannel/main.go  /START1 OMIT/,/END1 OMIT/

* The or-channel...

.code -edit src/02-ConcurrencyPatterns/orChannel/main.go  /START2 OMIT/,/END2 OMIT/

* The or-channel...

- or function enables to combine any number of channels together into a single channel that will close as soon as any of its component channels are closed, or written to. 

- main body of the function, and where the recursion happens. We create a goroutine so that we can wait for messages on our channels without blocking.

- every recursive call to or will at least have two channels.

* The or-channel...

.code -edit src/02-ConcurrencyPatterns/orChannel/main.go  /START3 OMIT/,/END3 OMIT/

* The or-channel...

- This function simply creates a channel that will close when the time specified in the after elapses.

- Notice that despite placing several channels in our call to or that take various times to close, our channel that closes after one second causes the entire channel created by the call to or to close.

- This pattern is useful to employ at the intersection of modules in your system. At these intersections, you tend to have multiple conditions for canceling trees of goroutines through your call stack. 

* Error Handling

- concurrent processes should send their errors to another part of your program that has complete information about the state of your program, and can make a more informed decision about what to do. 

* Error Handling..

.play -edit src/02-ConcurrencyPatterns/errorHandling/main.go  /START1 OMIT/,/END1 OMIT/

* Error Handling..

.play -edit src/02-ConcurrencyPatterns/errorHandling/main.go  /START2 OMIT/,/END2 OMIT/

* Error Handling..

- we create a type that encompasses both the *http.Response and the error possible from an iteration of the loop within our goroutine.

- checkStatus() returns a channel that can be read from to retrieve results of an iteration of our loop.

- we’ve successfully separated the concerns of error handling from our producer goroutine. 

- main() has more context about the running program, and can make more intelligent decisions about what to do with errors.

- errors should be considered first-class citizens when constructing values to return from goroutines. If your goroutine can produce errors, those errors should be tightly coupled with your result type, and passed along through the same lines of communication—just like regular synchronous functions.


* Pipelines

- A pipeline is a tool used to form an abstraction when your program needs to process streams, or batches of data. 

- stage of the pipeline - take data in, perform an operation on it, and pass the data back out.

- using a pipeline, you separate the concerns of each stage.

- ability to process individual stages concurrently.

- you can mix and match how stages are combined independent of modifying the stages.

- you can process each stage concurrent to upstream or downstream stages, and you can fan-out, or rate-limit portions of your pipeline. 

* properties of a pipeline stage

- A stage consumes and returns the same type.

- Channels are uniquely suited to constructing pipelines in Go. They can receive and emit values, they can safely be used concurrently, they can be ranged over.

* Pipelines

.play -edit src/02-ConcurrencyPatterns/pipeline01/main.go  /START1 OMIT/,/END1 OMIT/

* Pipelines

.play -edit src/02-ConcurrencyPatterns/pipeline01/main.go  /START2 OMIT/,/END2 OMIT/

* Pipelines

.play -edit src/02-ConcurrencyPatterns/pipeline01/main.go  /START3 OMIT/,/END3 OMIT/

* Pipelines

.play -edit src/02-ConcurrencyPatterns/pipeline01/main.go  /START4 OMIT/,/END4 OMIT/

* Pipelines..

-  Generator batch of data convert to a channel.

- each stage of the pipeline is executing concurrently.

- any stage only need wait for its inputs, and to be able to send its outputs.

- The stages are interconnected in two ways: by the common done channel, and by the channels that are passed into subsequent stages of the pipeline.

* Pipelines..

- Ranging over the incoming channel. When the incoming channel is closed, the range will exit.

- The send sharing a select statement with the done channel.

- select statement and done channel, which ensures that generator is preemptable even if it is blocked attempting to write to intStream.

* Fan-Out, Fan-In

- Sometimes, stages in your pipeline can be particularly computationally expensive. When this happens, upstream stages in your pipeline can become blocked while waiting for your expensive stages to complete.

- Fan-out is a term to describe the process of starting multiple goroutines to handle input from the pipeline

- Fan-in is a term to describe the process of combining multiple results into one channel.

* consider fanning out when

- Current computation doesn’t rely on values that the stage had calculated before.

- Computation takes a long time to run.

* consider fan in when

- Fan-in multiplex or join together multiple streams of data into a single stream. 


* Fan-Out, Fan-In

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START1 OMIT/,/END1 OMIT/

* Fan-Out, Fan-In

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START2 OMIT/,/END2 OMIT/

* Fan-Out, Fan-In

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START3 OMIT/,/END3 OMIT/

* Fan-Out, Fan-In

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START4 OMIT/,/END4 OMIT/

* Fan-Out, Fan-In

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START5 OMIT/,/END5 OMIT/

* Fan-Out, Fan-In

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START6 OMIT/,/END6 OMIT/

* Fan-Out, Fan-In

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START7 OMIT/,/END7 OMIT/

* Fan-Out, Fan-In

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START8 OMIT/,/END8 OMIT/

* Fan-Out, Fan-In

- We now have eight goroutines pulling from the random number generator and attempting to determine whether the number is prime. 

- fanning multiplexing or joining together multiple streams of data into a single stream.

- fanning in involves creating the multiplexed channel consumers will read from, and then spinning up one goroutine for each incoming channel, and one goroutine to close the multiplexed channel when the incoming channels have all been closed. 

* The bridge-channel

- every time a pipeline stage is restarted within a new goroutine, a new channel would be created. This means we’d effectively have a sequence of channels.

- bridge-channel is useful to consume values from a sequence of channels.

- bridging the channels destructure the channel of channels into a simple channel

* Bridge-channel

.code -edit src/02-ConcurrencyPatterns/fanout/main.go  /START1 OMIT/,/END1 OMIT/

* Bridge-channel

.code -edit src/02-ConcurrencyPatterns/bridge/main.go  /START2 OMIT/,/END2 OMIT/

* Bridge-channel

.code -edit src/02-ConcurrencyPatterns/bridge/main.go  /START3 OMIT/,/END3 OMIT/

* Bridge-channel

.code -edit src/02-ConcurrencyPatterns/bridge/main.go  /START4 OMIT/,/END4 OMIT/

- we can use the channel of channels from within a single range statement 

* Queuing

- Begin accepting work for your pipeline even though the pipeline is not yet ready for more.

- While introducing queuing into your system is very useful, it’s usually one of the last techniques you want to employ when optimizing your program. Adding queuing prematurely can hide synchronization issues such as deadlocks and livelocks

- Queuing will almost never speed up the total runtime of your program; it will only allow the program to behave differently.

* Queuing...

- Consider pipeline with stages, acceptConnection stage, processRequest stage

- you wouldn’t want connections to your program to begin timing out because your processRequest stage was blocking your acceptConnection stage.

-  introducing a queue isn’t that the runtime of one of stages has been reduced, but rather that the time it’s in a blocking state is reduced. 

- users would likely experience lag in their requests, but they wouldn’t be denied service altogether.

- true utility of queues is to decouple stages so that the runtime of one stage has no impact on the runtime of another. 

* Queuing...

- situations in which queuing can increase the overall performance of your system. The only applicable situations are:

- If batching requests in a stage saves time.

- If delays in a stage produce a feedback loop into the system.

* Queuing...

- queuing should be implemented either:

- At the entrance to your pipeline.

- In stages where batching will lead to higher efficiency.

* how large our queues should be.

- Little’s Law - L=λW

- L = the average number of units in the system.

- λ = the average arrival rate of units.

- W = the average time a unit spends in the system.

- if 1 request (r) takes about 1 second, there are 3 stages 
    3r = λr/s * 1s
    3r/s = λr/s
    λr/s = 3r/s

- we can handle three requests per second. so queue size needs to 3.

* The context Package

- context package serves two primary purposes:

- provide an API for canceling branches of your call-graph.

- provide a data-bag for transporting request-scoped data through your call-graph.

* Context Package..

    type Context interface {
        Deadline() (deadline time.Time, ok bool)
        Done() <-chan struct{}
        Err() error
        Value(key interface{}) interface{}
    }

* Context Package..

- Deadline function to indicate if a goroutine will be canceled after a certain time

- Err method that will return non-nil if the goroutine was canceled. 

- Value method used to hold request-specific information.

* Context Package.. cancellation..

- A goroutine may want to cancel its children.

- Any blocking operations within a goroutine need to be preemptable so that it may be canceled.

* Context Package..

- Context is immutable

- to affect the behavior of cancellations in functions below a current function in the call stack, we have functions

    func WithCancel(parent Context) 
                    (ctx Context, cancel CancelFunc)
    func WithDeadline(parent Context, deadline time.Time) 
                    (Context, CancelFunc)
    func WithTimeout(parent Context, timeout time.Duration) 
                    (Context, CancelFunc)

* Context Package..

- The functions all generate new instances of a Context with the options relative to these functions.

- WithCancel returns a new Context that closes its done channel when the returned cancel function is called.

- WithDeadline returns a new Context that closes its done channel when the machine’s clock advances past the given deadline

- WithTimeout returns a new Context that closes its done channel after the given timeout duration.

* Context Package..

- If your function needs to cancel functions below it in the call-graph in some manner, it will call one of these functions and pass in the Context it was given, and then pass the Context returned into its children.

- successive layers of the call-graph can create a Context that adheres to their needs without affecting their parents.

* Context Package..

- instances of a Context are meant to flow through your program’s call-graph. 

- Instances of context.Context may look equivalent from the outside, but internally they may change at every stack-frame. For this reason, it’s important to always pass instances of Context into your functions.

* Context Package..

    func Background() Context
    func TODO() Context

- Background simply returns an empty Context. 

- TODO is not meant for use in production, but also returns an empty Context.

- TODO’s intended purpose is to serve as a placeholder for when you don’t know which Context to utilize, or if you expect your code to be provided with a Context, but the upstream code hasn’t yet furnished one.

* Context Package..

src/context/main.go

- main creates a new Context with context.Background() and wraps it with context.WithCancel to allow for cancellations.

- genGreeting wraps its Context with context.WithTimeout. This will automatically cancel the returned Context after 1 second, thereby canceling any children it passes the Context into, namely locale.

- locale() returns the reason why the Context was canceled. This error will bubble all the way up to main

* Context Package..

- genGreeting was able to build up a custom context.Context to meet its needs without having to affect its parent’s Context.

- If genGreeting were to return successfully, and printGreeting needed to make another call, it could do so without leaking information about how genGreeting operated. 

- This composability enables you to write large systems without mixing concerns throughout your call-graph.

* Context Package.. data-bag..

- when a function creates a goroutine and Context, it’s starting a process that will service requests, and functions further down the stack may need information about the request.

* Context Package.. data-bag..

.play -edit src/02-ConcurrencyPatterns/context02/main.go  /START OMIT/,/END OMIT/

* Error propogation

- how issues propagate through your system, and how they end up being represented to the user is important.

- Error should depict, what happened, when and where it occured, complete stack strace.

- Errors should contains time on the machine in UTC

- User friendly message. 

- Hash of stack trace as log ID to reference in corresponding log that contains full information.

* Errors...

- It’s possible to place all errors into one of two categories:

    Bugs

    Known edge cases (e.g., broken network connections, failed disk writes, etc.)

-  At boundaries of each component, all incoming errors must be wrapped in a well-formed error 

- module boundaries we convert the error to our module’s error type—potentially filling in pertinent information. 

- if incoming error is not well formed, simply ferry the malformed error up the stack to indicate a bug.

* Errors...

- src/02-ConcurrencyPatterns/errors01/main.go

* Errors...

- we store lowest-level error, stack trace, log id.

- "lowlevel" module wrap the raw error from calling os.Stat with a customized error.

- err.(IntermediateErr) - check to see if the error is of the expected type. If it is, we know it’s a well-crafted error, and we can simply pass its message on to the user.

- handleError(1, err, msg) - bind the log and error message together with an ID of 1

* Heartbeats

- Heartbeats are a way for concurrent processes to signal life to outside parties. 

- Two types: 

- Heartbeats that occur on a time interval.

- Heartbeats that occur at the beginning of a unit of work.

* Heartbeats.. interval

- src/02-ConcurrencyPatterns/heartbeat01/main.go

* Heartbeats.. interval

- <1> set up a channel to send heartbeats on

- <2> heartbeat to pulse at the pulseInterval

- <4> default clause, We must always guard against the fact that no one may be listening to our heartbeat. 

- Notice that because we might be sending out multiple pulses while we wait for input, or multiple pulses while waiting to send results, all the select statements need to be within for loops.

* Heartbeats.. interval

- <4> select on the heartbeat. 

- When there are no results, we are at least guaranteed a message from the heartbeat channel every timeout/2. If we don’t receive it, we know there’s something wrong with the goroutine itself.

- By using a heartbeat, we can avoid deadlock, and we remain deterministic by not having to rely on a longer timeout. 

- Heartbeats let us know that long-running goroutines remain up, but are just taking a while to produce a value to send on the values channel.

* Heartbeats.. beginning of a unit of work..

- src/02-ConcurrencyPatterns/heartbeat02/main.go

* Heartbeats.. beginning of a unit of work..

- create the heartbeat channel with a buffer of one. This ensures that there’s always at least one pulse sent out even if no one is listening in time for the send to occur.

- we set up a separate select block for the heartbeat. We don’t want to include this in the same select block as the send on results because if the receiver isn’t ready for the result, they’ll receive a pulse instead, and the current value of the result will be lost. We also don’t include a case statement for the done channel since we have a default case that will just fall through.

- we receive one pulse for every result.

- if you only care that the goroutine has started doing its work, this style of heartbeat is simple. 

* Heartbeats... interval.. concurrent test

- src/02-ConcurrencyPatterns/heartbeat03/main.go

* Heartbeats... interval.. concurrent test

- <1> require two loops: one to range over our list of numbers, and this inner loop to run until the number is successfully sent on the intStream.

- <4> wait for the first heartbeat to occur to indicate we’ve entered the goroutine’s loop.

* Rate Limiting

- constrains the number of times some kind of resource is accessed to some finite number per unit of time. 

- The resource can be anything: API connections, disk reads/writes, network packets, errors

- By rate limiting a system, you prevent entire classes of attack vectors against your system. 

- fill up your service’s disk either with log messages or valid requests. if you don’t rate limit requests to your system, you cannot easily secure it.

* Rate Limiting..

- Most rate limiting is done by utilizing an algorithm called the token bucket. 

- every time you need to access a resource, you reach into the bucket and remove a token. 

- if no access token is available, you either have to queue your request until a token becomes available, or deny the request.

- In the token bucket algorithm, we define r to be the rate at which tokens are added back to the bucket. 

- we have to wait until new tokens become available, we limit our operations to that refresh rate.

* Rate Limiting..

- Burstiness  means how many requests can be made when the bucket is full.

- Normally a rate limiter would be running on a server so the users couldn’t trivially bypass it. Production systems might also include a client-side rate limiter to help prevent the client from making unnecessary calls only to be denied.


* Rate Limiting..example..

- Two API one for reading a file, and one for resolving a domain name to an IP address. 

- The driver needs to read 10 files and resolve 10 addresses, they are done concurrently.

- examples uses an implementation of a token bucket rate limiter from the golang.org/x/time/rate package.

- NewLimiter, takes two parameters: r and b. r is the rate of replishment, and b is the bucket depth.

- rate.Limit(events/timePeriod.Seconds()) - number of operations per time measurement

- we create a rate.Limiter, we use it to block our requests until we’re given an access token. We can do that with the Wait method.

* Rate Limiting..example..

- src/02-ConcurrencyPatterns/rate-limit/main.go

- <1> we set the rate limit for all API connections to one event per second.

- <2> we wait on the rate limiter to have enough access tokens for us to complete our request.

- we are completing a request once a second, even though we were fielding all of our API requests simultaneously.

* Healing Unhealthy Goroutines

- In long-lived processes such as daemons, it’s very common to have a set of long-lived goroutines.

- it can be very easy for a goroutine to become stuck in a bad state from which it cannot recover without external help.

- it can be useful to create a mechanism that ensures your goroutines remain healthy and restarts them if they become unhealthy.

* Healing Unhealthy Goroutines...

- To heal goroutines, we’ll use our heartbeat pattern to check up on the liveliness of the goroutine we’re monitoring. 

* Healing Unhealthy Goroutines...

- src/02-ConcurrencyPatterns/rate-limit/main.go

- <1> - signature of a goroutine that can be monitored and restarted. 

- <2> - we see that a steward takes in a timeout for the goroutine it will be monitoring and a function, startGoroutine, to start the goroutine it’s monitoring.

- <3> - closure that encodes a consistent way to start the goroutine we’re monitoring.

- <4> - we create a new channel that we’ll pass into the ward goroutine in case we need to signal that it should halt.

* Healing Unhealthy Goroutines...

- <5> - We want the ward goroutine to halt if either the steward is halted, or the steward wants to halt the ward goroutine, so we wrap both done channels in a logical-or. 

- <7> - we see that if we receive the ward’s pulse, we continue our monitoring loop.

- <8> - if we don’t receive a pulse from the ward within our timeout period, we request that the ward halt and we begin a new ward goroutine. 

* Healing Unhealthy Goroutines...

- <1> goroutine isn’t doing anything but waiting to be canceled. 

- <2> create a steward for the goroutine doWork starts. We set the timeout for doWork at four seconds.

- <3> we halt the steward and its ward after nine seconds so that our example will end.

- <4> we start the steward and range over its pulses to prevent our example from halting.



